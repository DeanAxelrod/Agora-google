<!DOCTYPE html>
<html>
<head>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands"></script>
  <script src="https://cdn.agora.io/sdk/release/AgoraRTCSDK-3.6.9.js"></script>
  <style>
    body { 
      font-family: Arial, sans-serif; 
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100vh;
      margin: 0;
      padding: 0;
    }
    .button-container { 
      display: flex; 
      gap: 20px; 
    }
    button {
      padding: 15px 30px; 
      cursor: pointer;
      border: 1px solid #ccc;
      background: none;
      font-size: 16px; 
      min-width: 150px;
      transition: all 0.3s ease;
    }
    button:disabled { 
      cursor: not-allowed;
      opacity: 0.5;
    }
  </style>
</head>
<body>
  <div class="button-container">
    <button id="startBtn">Start Recording</button>
    <button id="stopBtn" disabled>Stop Recording</button>
  </div>

  <script>
    const appId = "25336bcd01664c70870804ba0b7e1b30";
    const modelURL = "https://deanaxelrod.github.io/Google-TM/model.json";
    const classLabels = ["Noise", "Sad Dog", "Excited Dog", "Disappointed Dog", "Growl", "Whimper", "Bark"];

    let mediaRecorder = null;
    let recordedChunks = [];
    let model = null;

    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const statusEl = document.getElementById('recordingStatus');
    const resultEl = document.getElementById('classificationResult');
    const permissionMsgEl = document.getElementById('permissionMessage');

    function debugLog(message) {
      const debugDiv = document.getElementById('debug');
      const logEntry = document.createElement('p');
      logEntry.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;
      debugDiv.appendChild(logEntry);
      debugDiv.scrollTop = debugDiv.scrollHeight;
      console.log(message); // Also log to console for additional debugging
    }

    function setRecordingState(recording) {
      startBtn.disabled = recording;
      stopBtn.disabled = !recording;
      statusEl.textContent = `Recording Status: ${recording ? 'Recording' : 'Ready'}`;

      if (recording) {
        stopBtn.classList.add('recording');
      } else {
        stopBtn.classList.remove('recording');
      }
    }

    async function checkMicrophonePermission() {
      try {
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
          throw new Error('getUserMedia not supported');
        }

        // Try to query permissions if supported
        if (navigator.permissions) {
          const permissionStatus = await navigator.permissions.query({ name: 'microphone' });
          debugLog(`Microphone Permission Status: ${permissionStatus.state}`);

          permissionStatus.onchange = () => {
            debugLog(`Microphone permission changed to: ${permissionStatus.state}`);
          };

          if (permissionStatus.state === 'denied') {
            permissionMsgEl.textContent = 'Microphone access is blocked. Please enable in device settings.';
            throw new Error('Microphone access denied');
          }
        }

        // Attempt to get user media to verify real-time access
        await navigator.mediaDevices.getUserMedia({ 
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          } 
        });

        permissionMsgEl.textContent = ''; // Clear any previous error messages
        return true;
      } catch (error) {
        debugLog(`Microphone Permission Error: ${error.message}`);
        permissionMsgEl.textContent = `Microphone Access Error: ${error.message}. Please check browser settings.`;
        startBtn.disabled = true;
        return false;
      }
    }

    async function createSpectrogram(audioBuffer) {
      try {
        debugLog("Creating spectrogram...");

        const audioData = audioBuffer.getChannelData(0);
        const fftSize = 512;
        const hopSize = fftSize / 2;
        const numFrames = Math.floor((audioData.length - fftSize) / hopSize);

        const spectrogramData = [];

        for (let i = 0; i < numFrames; i++) {
          const startIdx = i * hopSize;
          const frameData = audioData.slice(startIdx, startIdx + fftSize);

          if (frameData.length === fftSize) {
            const tensorFrame = tf.tensor1d(frameData);
            const windowedFrame = tensorFrame.mul(tf.signal.hammingWindow(fftSize));
            const fft = tf.spectral.rfft(windowedFrame);
            const magnitude = tf.abs(fft);

            spectrogramData.push(magnitude.arraySync());
            fft.dispose();
            tensorFrame.dispose();
          }
        }

        const spectrogramTensor = tf.tensor2d(spectrogramData);
        debugLog(`Spectrogram created with shape: ${spectrogramTensor.shape}`);

        const targetHeight = 43;
        const targetWidth = 232;

        const spectrogramWithChannel = spectrogramTensor.reshape([1, spectrogramTensor.shape[0], spectrogramTensor.shape[1], 1]);
        const resizedSpectrogram = tf.image.resizeBilinear(spectrogramWithChannel, [targetHeight, targetWidth]);
        spectrogramTensor.dispose();

        const normalizedSpectrogram = resizedSpectrogram.div(tf.max(resizedSpectrogram));
        return normalizedSpectrogram.reshape([1, targetHeight, targetWidth, 1]);
      } catch (error) {
        debugLog("Error creating spectrogram: " + error.message);
        throw error;
      }
    }

    async function classifyAudio(audioBlob) {
      try {
        debugLog("Starting classification...");
        const audioContext = new AudioContext();
        const arrayBuffer = await audioBlob.arrayBuffer();

        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
        debugLog("Audio decoded, duration: " + audioBuffer.duration);

        const spectrogram = await createSpectrogram(audioBuffer);
        const prediction = await model.predict(spectrogram).data();
        spectrogram.dispose();

        classLabels.forEach((label, idx) => {
          debugLog(`${label}: ${(prediction[idx] * 100).toFixed(2)}%`);
        });

        const resultIndex = prediction.indexOf(Math.max(...prediction));
        const classificationLabel = classLabels[resultIndex];

        // Simplified message
        const simpleMessage = {
          type: 'audioClassification',
          classification: classificationLabel
        };

        debugLog("Classification result: " + classificationLabel);
        debugLog("Attempting to send message");
        debugLog("Message content: " + JSON.stringify(simpleMessage));

        // Try different message sending approaches
        try {
          if (window.ReactNativeWebView) {
            debugLog("Using ReactNativeWebView.postMessage");
            window.ReactNativeWebView.postMessage(JSON.stringify(simpleMessage));
          } else if (window.webkit && window.webkit.messageHandlers) {
            debugLog("Using webkit.messageHandlers");
            window.webkit.messageHandlers.message.postMessage(simpleMessage);
          } else {
            debugLog("Using window.parent.postMessage");
            window.parent.postMessage(simpleMessage, '*');
          }
          debugLog("Message sent via available channel");
        } catch (sendError) {
          debugLog("Error sending message: " + sendError.message);
        }

        debugLog("Classification complete: " + classificationLabel);
        return classificationLabel;
      } catch (error) {
        debugLog("Error in classifyAudio: " + error.message);
        throw error;
      }
    }

    async function startRecording() {
      try {
        // Ensure microphone permission is granted
        const hasPermission = await checkMicrophonePermission();
        if (!hasPermission) {
          debugLog("Microphone permission not granted");
          return;
        }

        debugLog("Starting recording...");
        setRecordingState(true);

        const stream = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          } 
        });

        mediaRecorder = new MediaRecorder(stream);
        recordedChunks = [];

        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            recordedChunks.push(event.data);
          }
        };

        mediaRecorder.onstart = () => {
          debugLog("MediaRecorder started");
        };

        mediaRecorder.start();
      } catch (error) {
        debugLog("Error starting recording: " + error.message);
        permissionMsgEl.textContent = `Recording Error: ${error.message}`;
        setRecordingState(false);
      }
    }

    async function stopRecording() {
      try {
        debugLog("Stopping recording...");
        statusEl.textContent = "Recording Status: Processing...";

        if (mediaRecorder && mediaRecorder.state !== 'inactive') {
          await new Promise(resolve => {
            mediaRecorder.onstop = resolve;
            mediaRecorder.stop();
          });
          debugLog("MediaRecorder stopped");
        }

        if (recordedChunks.length > 0) {
          const audioBlob = new Blob(recordedChunks, { type: 'audio/webm' });
          debugLog("Processing audio...");

          try {
            const classificationLabel = await classifyAudio(audioBlob);
            resultEl.textContent = "Classification Result: " + classificationLabel;
            
            // Message will be sent from classifyAudio function
            debugLog("Classification complete: " + classificationLabel);
          } catch (error) {
            debugLog("Classification failed: " + error.message);
            resultEl.textContent = "Classification Result: Error";
            window.parent.postMessage({
              type: 'error',
              message: error.message
            }, '*');
          }
        }

        setRecordingState(false);
      } catch (error) {
        debugLog("Error stopping recording: " + error.message);
        setRecordingState(false);
      }
    }

    async function initialize() {
      try {
        debugLog("Loading model...");
        await tf.setBackend('cpu');
        model = await tf.loadLayersModel(modelURL);
        debugLog("Model loaded successfully");
        
        // Add test message
        setTimeout(() => {
          debugLog("Sending test message");
          try {
            window.parent.postMessage({
              type: 'test',
              message: 'hello'
            }, '*');
            debugLog("Test message sent");
          } catch (error) {
            debugLog("Error sending test message: " + error.message);
          }
        }, 2000);  // Send test message after 2 seconds

        startBtn.disabled = false;
        statusEl.textContent = "Recording Status: Ready";
      } catch (error) {
        debugLog("Initialization error: " + error.message);
        startBtn.disabled = true;
        statusEl.textContent = "Recording Initialization Failed";
        permissionMsgEl.textContent = `Initialization Error: ${error.message}`;
      }
    }

    // Event Listeners
    startBtn.addEventListener('click', async () => {
      try {
        // Ensure this is directly triggered by user interaction
        await checkMicrophonePermission();
        await startRecording();
      } catch (error) {
        debugLog("Recording start error: " + error.message);
      }
    });

    stopBtn.addEventListener('click', stopRecording);

    window.addEventListener('beforeunload', () => {
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
      }
    });

    // Initialize on page load
    initialize();
  </script>
</body>
</html>
