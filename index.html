<!DOCTYPE html>
<html>
<head>
  <title>Agora Voice Recorder with Classification</title>
  <meta name="permissions-policy" content="microphone=*, camera=()">
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands"></script>
  <script src="https://cdn.agora.io/sdk/release/AgoraRTCSDK-3.6.9.js"></script>
  <style>
    body { font-family: Arial, sans-serif; }
    .button-container { margin: 20px 0; }
    button {
      margin: 5px; padding: 15px 30px; cursor: pointer;
      background-color: #4CAF50; color: white; border: none;
      border-radius: 4px; font-size: 16px; min-width: 200px;
      transition: all 0.3s ease;
    }
    button:disabled { background-color: #cccccc; cursor: not-allowed; }
    .stop-button { background-color: #cccccc; }
    .stop-button.recording { background-color: #f44336 !important; }  /* Red when recording */
    #debug { margin-top: 20px; padding: 10px; border: 1px solid #ccc; max-height: 300px; overflow-y: auto; }
    .status { font-size: 18px; margin: 10px 0; }
  </style>
</head>
<body>
  <h1>Agora Voice Recorder with Classification</h1>
  <div class="button-container">
    <button id="startBtn">Start Recording</button>
    <button id="stopBtn" class="stop-button" disabled>Stop Recording</button>
  </div>
  <p id="recordingStatus" class="status">Recording Status: Ready</p>
  <p id="classificationResult" class="status">Classification Result: N/A</p>
  <div id="debug"></div>

  <script>
    const appId = "25336bcd01664c70870804ba0b7e1b30";
    const modelURL = "https://deanaxelrod.github.io/Google-TM/model.json";
    const classLabels = ["Noise", "Sad Dog", "Excited Dog", "Disappointed Dog", "Growl", "Whimper", "Bark"];

    let mediaRecorder = null;
    let recordedChunks = [];
    let model = null;

    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const statusEl = document.getElementById('recordingStatus');
    const resultEl = document.getElementById('classificationResult');

    function debugLog(message) {
      const debugDiv = document.getElementById('debug');
      const logEntry = document.createElement('p');
      logEntry.textContent = message;
      debugDiv.appendChild(logEntry);
      debugDiv.scrollTop = debugDiv.scrollHeight;
    }

    function setRecordingState(recording) {
      startBtn.disabled = recording;
      stopBtn.disabled = !recording;
      statusEl.textContent = `Recording Status: ${recording ? 'Recording' : 'Ready'}`;

      // Add or remove the 'recording' class based on the state
      if (recording) {
        stopBtn.classList.add('recording');
      } else {
        stopBtn.classList.remove('recording');
      }
    }

    async function createSpectrogram(audioBuffer) {
      try {
        debugLog("Creating spectrogram...");

        const audioData = audioBuffer.getChannelData(0);
        const fftSize = 512;
        const hopSize = fftSize / 2;
        const numFrames = Math.floor((audioData.length - fftSize) / hopSize);

        const spectrogramData = [];

        for (let i = 0; i < numFrames; i++) {
          const startIdx = i * hopSize;
          const frameData = audioData.slice(startIdx, startIdx + fftSize);

          if (frameData.length === fftSize) {
            const tensorFrame = tf.tensor1d(frameData);
            const windowedFrame = tensorFrame.mul(tf.signal.hammingWindow(fftSize));
            const fft = tf.spectral.rfft(windowedFrame);
            const magnitude = tf.abs(fft);

            spectrogramData.push(magnitude.arraySync());
            fft.dispose();
            tensorFrame.dispose();
          }
        }

        const spectrogramTensor = tf.tensor2d(spectrogramData);
        debugLog(`Spectrogram created with shape: ${spectrogramTensor.shape}`);

        // Adjust the target shape to [43, 232]
        const targetHeight = 43; // Expected by the model
        const targetWidth = 232; // Expected by the model

        // Add an extra dimension (channel) before resizing: [height, width, 1]
        const spectrogramWithChannel = spectrogramTensor.reshape([1, spectrogramTensor.shape[0], spectrogramTensor.shape[1], 1]);

        // Resize the spectrogram to match the target dimensions
        const resizedSpectrogram = tf.image.resizeBilinear(spectrogramWithChannel, [targetHeight, targetWidth]);
        spectrogramTensor.dispose();

        // Normalize the spectrogram
        const normalizedSpectrogram = resizedSpectrogram.div(tf.max(resizedSpectrogram));

        // Return the spectrogram reshaped to match model input shape (1, 43, 232, 1)
        return normalizedSpectrogram.reshape([1, targetHeight, targetWidth, 1]);
      } catch (error) {
        debugLog("Error creating spectrogram: " + error.message);
        throw error;
      }
    }

    async function classifyAudio(audioBlob) {
      try {
        debugLog("Starting classification...");
        const audioContext = new AudioContext();
        const arrayBuffer = await audioBlob.arrayBuffer();

        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
        debugLog("Audio decoded, duration: " + audioBuffer.duration);

        const spectrogram = await createSpectrogram(audioBuffer);
        const prediction = await model.predict(spectrogram).data();
        spectrogram.dispose();

        classLabels.forEach((label, idx) => {
          debugLog(`${label}: ${(prediction[idx] * 100).toFixed(2)}%`);
        });

        const resultIndex = prediction.indexOf(Math.max(...prediction));
        return classLabels[resultIndex];
      } catch (error) {
        debugLog("Classification error: " + error.message);
        throw error;
      }
    }

// Replace the startRecording function with:
async function startRecording() {
  try {
    debugLog("Requesting permissions...");
    
    // First explicitly request permissions
    const permissionResult = await navigator.permissions.query({ name: 'microphone' });
    if (permissionResult.state === 'denied') {
      throw new Error('Microphone permission denied');
    }
    
    debugLog("Starting recording...");
    setRecordingState(true);

   const stream = await navigator.mediaDevices.getUserMedia({ 
    audio: true,
    video: false
}).catch(function(err) {
    debugLog("Need to request permissions first");
    return navigator.permissions.query({name:'microphone'})
      .then(function(permissionStatus) {
        if (permissionStatus.state === 'granted') {
            return navigator.mediaDevices.getUserMedia({ audio: true });
        } else {
            throw new Error("Please allow microphone access in your browser");
        }
    });
});

    // Create and resume AudioContext after user gesture
    const audioContext = new AudioContext();
    await audioContext.resume();

    mediaRecorder = new MediaRecorder(stream);
    recordedChunks = [];

    mediaRecorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        recordedChunks.push(event.data);
      }
    };

    mediaRecorder.onstart = () => {
      debugLog("MediaRecorder started");
    };

    mediaRecorder.start();
 } catch (error) {
    debugLog("Error starting recording: " + error.message);
    setRecordingState(false);
    recordedChunks = [];  // Clear any data
    window.parent.postMessage("Error: " + error.message, '*');
    return;  // Stop execution here
}

   async function stopRecording() {
    try {
        debugLog("Stopping recording...");
        statusEl.textContent = "Recording Status: Processing...";

        // Add check for valid recording at the start
        if (!mediaRecorder || mediaRecorder.state === 'inactive' || recordedChunks.length === 0) {
            debugLog("No valid recording to process");
            window.parent.postMessage("Error: No audio was recorded. Please allow microphone access.", '*');
            return;
        }

        if (mediaRecorder && mediaRecorder.state !== 'inactive') {
            await new Promise(resolve => {
                mediaRecorder.onstop = resolve;
                mediaRecorder.stop();
            });
            debugLog("MediaRecorder stopped");
        }

        if (recordedChunks.length > 0) {
          const audioBlob = new Blob(recordedChunks, { type: 'audio/webm' });
          debugLog("Processing audio...");

          try {
            const classificationLabel = await classifyAudio(audioBlob);
            resultEl.textContent = "Classification Result: " + classificationLabel;
            if (recordedChunks.length === 0) {
    debugLog("No audio was recorded");
    window.parent.postMessage("Error: No audio recorded due to microphone permissions", '*');
    return;
}
window.parent.postMessage(classificationLabel, '*');
            debugLog("Classification complete: " + classificationLabel);
          } catch (error) {
            debugLog("Classification failed: " + error.message);
            resultEl.textContent = "Classification Result: Error";
          }
        }

        setRecordingState(false);
      } catch (error) {
        debugLog("Error stopping recording: " + error.message);
        setRecordingState(false);
      }
    }

    async function initialize() {
      try {
        debugLog("Loading model...");
        await tf.setBackend('cpu');
        model = await tf.loadLayersModel(modelURL);
        debugLog("Model loaded successfully");
      } catch (error) {
        debugLog("Initialization error: " + error.message);
        startBtn.disabled = true;
        statusEl.textContent = "Recording Status: Initialization Failed";
      }
    }

    startBtn.addEventListener('click', startRecording);
    stopBtn.addEventListener('click', stopRecording);

    window.addEventListener('beforeunload', () => {
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
      }
    });

    initialize();
  </script>
</body>
</html>
